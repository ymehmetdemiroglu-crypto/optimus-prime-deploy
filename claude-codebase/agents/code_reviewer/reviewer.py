"""
Code Reviewer Agent - Analyzes code quality and provides improvement suggestions.

Purpose:
- Review code for bugs, anti-patterns, and issues
- Suggest improvements and optimizations
- Check code style and best practices
- Generate actionable review reports

Token Optimization:
- Focus on changed code sections only
- Use AST parsing instead of full Claude analysis for simple checks
- Cache common patterns and rules
- Batch multiple files in single review
"""

from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
from enum import Enum
import re
from ..base_agent import BaseAgent


class IssueSeverity(Enum):
    """Severity levels for code issues."""
    CRITICAL = "critical"      # Must fix (security, bugs)
    HIGH = "high"             # Should fix (performance, reliability)
    MEDIUM = "medium"         # Nice to fix (maintainability)
    LOW = "low"              # Optional (style, minor improvements)
    INFO = "info"            # Informational only


@dataclass
class CodeIssue:
    """
    Represents a code issue found during review.
    
    Attributes:
        file_path: Path to file with issue
        line_number: Line where issue occurs
        severity: Issue severity level
        category: Type of issue (bug, style, performance, etc.)
        description: What the problem is
        suggestion: How to fix it
        code_snippet: Relevant code snippet
    """
    file_path: str
    line_number: int
    severity: IssueSeverity
    category: str
    description: str
    suggestion: str
    code_snippet: str = ""


@dataclass
class ReviewReport:
    """
    Code review report.
    
    Attributes:
        files_reviewed: Number of files reviewed
        issues: List of all issues found
        summary: High-level summary
        metrics: Code quality metrics
    """
    files_reviewed: int
    issues: List[CodeIssue] = field(default_factory=list)
    summary: str = ""
    metrics: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def critical_count(self) -> int:
        """Count critical issues."""
        return sum(1 for i in self.issues if i.severity == IssueSeverity.CRITICAL)
    
    @property
    def high_count(self) -> int:
        """Count high severity issues."""
        return sum(1 for i in self.issues if i.severity == IssueSeverity.HIGH)
    
    @property
    def total_issues(self) -> int:
        """Total number of issues."""
        return len(self.issues)


class CodeReviewer(BaseAgent):
    """
    Reviews code for quality, bugs, and improvements.
    
    Expected Operations:
        - review_file(file_path): Review single file
        - review_changes(diff): Review code changes
        - suggest_improvements(code): Get improvement suggestions
        - generate_report(): Create review report
    
    Returns:
        - ReviewReport with findings and suggestions
    
    Best Practices:
        1. Focus on high-impact issues first
        2. Provide specific, actionable suggestions
        3. Include code examples in suggestions
        4. Prioritize security and correctness
        5. Balance automation with human judgment
    
    Token Savings:
        - Static analysis first: 70-80% savings vs full AI review
        - Incremental reviews (changes only): 60-90% savings
        - Rule caching: 20-30% savings
        - Batch processing: 30-40% savings
    """
    
    def __init__(self, config: Dict[str, Any], logger=None):
        super().__init__(config, logger)
        
        self.issues: List[CodeIssue] = []
        self.rules_enabled = config.get('rules_enabled', True)
        self.auto_fix = config.get('auto_fix', False)
        
        # Define review rules (in production, load from config)
        self.rules = self._initialize_rules()
    
    def process(self, operation: str, **kwargs) -> Any:
        """
        Process code review operation.
        
        Args:
            operation: Operation type ('review', 'suggest', 'report')
            **kwargs: Operation-specific arguments
        
        Returns:
            Result depends on operation
        """
        if operation == 'review':
            return self.review_code(
                kwargs['code'],
                kwargs.get('file_path', 'unknown')
            )
        elif operation == 'suggest':
            return self.suggest_improvements(kwargs['code'])
        elif operation == 'report':
            return self.generate_report()
        else:
            raise ValueError(f"Unknown operation: {operation}")
    
    def review_code(self, code: str, file_path: str = "unknown") -> List[CodeIssue]:
        """
        Review code and identify issues.
        
        Args:
            code: Code to review
            file_path: Path to file being reviewed
        
        Returns:
            List of issues found
        """
        self.logger.info(f"Reviewing code: {file_path}")
        
        issues = []
        lines = code.split('\n')
        
        # Run automated checks
        for line_num, line in enumerate(lines, 1):
            # Check each rule
            for rule in self.rules:
                issue = rule['check'](line, line_num, file_path)
                if issue:
                    issues.append(issue)
        
        # Additional checks
        issues.extend(self._check_complexity(code, file_path))
        issues.extend(self._check_security(code, file_path))
        issues.extend(self._check_performance(code, file_path))
        
        # Store issues
        self.issues.extend(issues)
        
        # Track token usage (estimation)
        tokens_used = len(code) // 4  # Approximate
        self.track_tokens(tokens_used)
        
        self.logger.info(f"Found {len(issues)} issues in {file_path}")
        
        return issues
    
    def suggest_improvements(self, code: str) -> List[Dict[str, str]]:
        """
        Generate improvement suggestions for code.
        
        Args:
            code: Code to analyze
        
        Returns:
            List of improvement suggestions
        """
        suggestions = []
        
        # Check for common improvements
        if 'TODO' in code or 'FIXME' in code:
            suggestions.append({
                'type': 'technical_debt',
                'description': 'Code contains TODO/FIXME comments',
                'suggestion': 'Address pending tasks before production'
            })
        
        # Check for long functions
        if code.count('def ') > 0:
            avg_function_length = len(code.split('\n')) / code.count('def ')
            if avg_function_length > 50:
                suggestions.append({
                    'type': 'maintainability',
                    'description': 'Functions are too long',
                    'suggestion': 'Break down long functions into smaller, focused functions'
                })
        
        # Check for duplicated code patterns
        lines = code.split('\n')
        line_counts = {}
        for line in lines:
            stripped = line.strip()
            if len(stripped) > 20:  # Ignore short lines
                line_counts[stripped] = line_counts.get(stripped, 0) + 1
        
        duplicates = [line for line, count in line_counts.items() if count > 2]
        if duplicates:
            suggestions.append({
                'type': 'DRY_principle',
                'description': f'Found {len(duplicates)} duplicated code patterns',
                'suggestion': 'Extract duplicated code into reusable functions'
            })
        
        return suggestions
    
    def generate_report(self) -> str:
        """
        Generate formatted code review report.
        
        Returns:
            Formatted report string
        """
        if not self.issues:
            return "âœ“ No issues found. Code looks good!"
        
        # Group issues by severity
        by_severity = {}
        for issue in self.issues:
            severity = issue.severity.value
            if severity not in by_severity:
                by_severity[severity] = []
            by_severity[severity].append(issue)
        
        # Build report
        report = [
            "=" * 70,
            "CODE REVIEW REPORT",
            "=" * 70,
            f"\nTotal Issues Found: {len(self.issues)}",
            ""
        ]
        
        # Summary by severity
        for severity in [IssueSeverity.CRITICAL, IssueSeverity.HIGH, 
                        IssueSeverity.MEDIUM, IssueSeverity.LOW]:
            count = len(by_severity.get(severity.value, []))
            if count > 0:
                icon = "ðŸ”´" if severity == IssueSeverity.CRITICAL else "ðŸŸ¡" if severity == IssueSeverity.HIGH else "ðŸŸ¢"
                report.append(f"{icon} {severity.value.upper()}: {count}")
        
        report.extend([
            "",
            "=" * 70,
            "DETAILED FINDINGS:",
            "=" * 70
        ])
        
        # Detailed issues
        for severity in [IssueSeverity.CRITICAL, IssueSeverity.HIGH, 
                        IssueSeverity.MEDIUM, IssueSeverity.LOW]:
            issues_list = by_severity.get(severity.value, [])
            if not issues_list:
                continue
            
            report.append(f"\n{severity.value.upper()} ISSUES:")
            report.append("-" * 70)
            
            for issue in issues_list:
                report.extend([
                    f"\nðŸ“ File: {issue.file_path}",
                    f"ðŸ“ Line: {issue.line_number}",
                    f"ðŸ·ï¸  Category: {issue.category}",
                    f"â— Issue: {issue.description}",
                    f"ðŸ’¡ Suggestion: {issue.suggestion}"
                ])
                
                if issue.code_snippet:
                    report.extend([
                        "   Code:",
                        f"   > {issue.code_snippet}"
                    ])
                
                report.append("-" * 70)
        
        report.append("\n" + "=" * 70)
        
        return "\n".join(report)
    
    def _initialize_rules(self) -> List[Dict]:
        """Initialize code review rules."""
        return [
            {
                'name': 'no_print_statements',
                'check': lambda line, num, path: CodeIssue(
                    file_path=path,
                    line_number=num,
                    severity=IssueSeverity.MEDIUM,
                    category='debugging',
                    description='Print statement found (use logging instead)',
                    suggestion='Replace print() with proper logging',
                    code_snippet=line.strip()
                ) if 'print(' in line and not line.strip().startswith('#') else None
            },
            {
                'name': 'long_lines',
                'check': lambda line, num, path: CodeIssue(
                    file_path=path,
                    line_number=num,
                    severity=IssueSeverity.LOW,
                    category='style',
                    description='Line exceeds 100 characters',
                    suggestion='Break long lines for better readability',
                    code_snippet=line.strip()[:50] + "..."
                ) if len(line) > 100 else None
            },
            {
                'name': 'bare_except',
                'check': lambda line, num, path: CodeIssue(
                    file_path=path,
                    line_number=num,
                    severity=IssueSeverity.HIGH,
                    category='error_handling',
                    description='Bare except clause catches all exceptions',
                    suggestion='Catch specific exceptions instead of bare except',
                    code_snippet=line.strip()
                ) if 'except:' in line else None
            }
        ]
    
    def _check_complexity(self, code: str, file_path: str) -> List[CodeIssue]:
        """Check code complexity."""
        issues = []
        
        # Simple cyclomatic complexity check
        complexity_indicators = ['if ', 'elif ', 'for ', 'while ', 'and ', 'or ']
        total_complexity = sum(code.count(indicator) for indicator in complexity_indicators)
        
        if total_complexity > 20:
            issues.append(CodeIssue(
                file_path=file_path,
                line_number=0,
                severity=IssueSeverity.MEDIUM,
                category='complexity',
                description=f'High cyclomatic complexity ({total_complexity})',
                suggestion='Consider refactoring into smaller functions'
            ))
        
        return issues
    
    def _check_security(self, code: str, file_path: str) -> List[CodeIssue]:
        """Check for security issues."""
        issues = []
        
        # Check for common security issues
        if 'eval(' in code:
            issues.append(CodeIssue(
                file_path=file_path,
                line_number=0,
                severity=IssueSeverity.CRITICAL,
                category='security',
                description='Use of eval() detected - security risk',
                suggestion='Avoid eval(). Use safer alternatives like ast.literal_eval()'
            ))
        
        if 'exec(' in code:
            issues.append(CodeIssue(
                file_path=file_path,
                line_number=0,
                severity=IssueSeverity.CRITICAL,
                category='security',
                description='Use of exec() detected - security risk',
                suggestion='Avoid exec(). Refactor to use safer approaches'
            ))
        
        return issues
    
    def _check_performance(self, code: str, file_path: str) -> List[CodeIssue]:
        """Check for performance issues."""
        issues = []
        
        # Check for inefficient patterns
        if '+=' in code and 'for ' in code and 'str' in code.lower():
            issues.append(CodeIssue(
                file_path=file_path,
                line_number=0,
                severity=IssueSeverity.MEDIUM,
                category='performance',
                description='String concatenation in loop detected',
                suggestion='Use list.append() and "".join() instead for better performance'
            ))
        
        return issues
    
    def clear_issues(self) -> None:
        """Clear all stored issues."""
        self.issues.clear()
        self.logger.info("Cleared all issues")
